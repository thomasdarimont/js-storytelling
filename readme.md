# Visualize Spoken Text

The idea was to create a visual experience similar to the [CultureHubNode](https://github.com/mncmncmnc/CultureHubNode)
project.

This WIP toy project demonstrates the use of Google Chrome's `webkitSpeechRecognition` API.

## Running the example

The example is build with [parcel](https://github.com/parcel-bundler/parcel).  
To run the app just install `parcel` and run the following in the project root.

```
parcel index.html
```

Then browse to `http://localhost:1234`

To start the visualization click `start` and speak into your microphone.

# Next steps

- Integrate the [NCR Sentiment and Emotion Lexicons](http://sentiment.nrc.ca/lexicons-for-research/) for emotion aware visualizations.
- Implement some visualizations like those from the [CultureHubNode](https://github.com/mncmncmnc/CultureHubNode) project.